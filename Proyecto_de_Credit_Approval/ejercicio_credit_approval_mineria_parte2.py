# -*- coding: utf-8 -*-
"""Ejercicio_CREDIT_APPROVAL_mineria_Parte2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cUTySWNdHajMHjtNtFNC_NdD5N82_NY5

#Ejercicio Unidad 1 Aprende y Mejora.
# Estudiante: Leonardo Torres Velilla

Tomaremos en cuenta el caso presentado por el profesor, realizando un analisis exploratorio de datos, donde se identificaran columnas, tipo de datos, medidas estadisticas, outliers, graficos.
"""

"""Primero importamos las librerias necesarias para el analisis exploratorio de datos
"""
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""
Importamos el dataset que para este ejercicio es un .CSV
"""
df_base = pd.read_csv("/content/credit_approval.csv", header=None)

"""#1. CREACIÓN DE NOMBRES A LAS COLUMNAS"""

df_base.columns = ['Sexo', 'Edad', 'Deuda', 'Casado', 'Cliente_bancario', 'Nivel_educativo',
    'Etnia', 'Años_empleo', 'Incumplimiento_previo', 'Empleado', 'Calificación_crediticia',
    'Licencia_conducir', 'Ciudadanía', 'Código_postal', 'Ingresos', 'Aprobado']

#Vizualizacion del dataset
df_base.head()

#Ver información del dataset
df_base.info()

#Resumen estadistico
df_base.describe(include='all')

"""Según como nos indica el diccionario de datos se cambiará la columna Aprobado a tipo numérico, reemplazando el "+" por "1" y el "-" por "0"."""

df_base['Aprobado'] = df_base['Aprobado'].replace({'+': 1, '-': 0}).astype(int)

"""#2. ANALÍSIS DE LOS DATOS

Total de registros: 690
Total de columnas: 16

Tipos de datos
Numéricos: Edad, Deuda, Años_empleo, Calificación_crediticia, Ingresos.

Categóricos (object): Sexo, Casado, Cliente_bancario, etc.

Como punto importante a resaltar, la variable Edad aparece como (Object), esto debido a que contiene valores no numéricos como '?'

#3. LIMPIEZA INICIAL

  a. Tal como se ve en la descripcion de los valores en las columnas, se observa que hay valores en '?', motivo por el cual seran reemplazados por valores nulos.

  b. Convertir columnas numéricas a su tipo correcto.

  c. Identificar valores nulos.

  d. Eliminar duplicados nulos en caso de que existan.
"""

#cambiar los '?' por NaN
df_base = df_base.replace('?', np.nan)
df_base.describe(include='all')

#Conversion de variable Edad
df_base['Edad'] = pd.to_numeric(df_base['Edad'], errors='coerce')

#Verificar valores nulos y duplicados
print(df_base.isnull().sum())
print(df_base.duplicated().sum())

"""tal como observamos, las columnas que mas se ven afectadas son Sexo, Edad y Código_postal.

No se encontraron filas duplicadas.

#4. MANEJO DE VALORES FALTANTES.

En este paso tomaremos la variables de valores Numéricos que habíamos mencionado anteriormente y llenaremos los valores faltantes con la **media**. De igual manera las variables categóricas serán reemplazadas por la **moda**.

Luego volveremos a verificar si quedaron valores nulos.
"""

#Valores numéricos con la media
col_num = ["Edad"]
for col in col_num:
    df_base[col].fillna(df_base[col].mean(), inplace=True)

#Valores categóricas con la moda
col_cat = ["Sexo", "Casado", "Cliente_bancario", "Nivel_educativo", "Etnia", "Empleado", "Ciudadanía", "Código_postal"]
for col in col_cat:
    df_base[col].fillna(df_base[col].mode()[0], inplace=True)

# Verificación que no queden nulos
print("\nValores nulos después de limpieza:")
print(df_base.isnull().sum())

"""En conclusión podemos inferir que nuestra base ya no contiene valores nulos motivo por el cual podemos pasar a nuestro siguiente punto.

#5. ANALÍSIS DE ESTADÍSTICAS DESCRIPTTIVAS

- En este punto vamos a calcular la **media**, **mediana**, **desviasión estándar**, **mínimos**, **máximos**, **percentiles**.
- Distribución de variables numéricas.
- Detección y tratamiento de Outliers; en esta parte tomaremos la referencia indicada en la pagina del diccionario de datos, la cual será:

Si un outlier es extremo, lo eliminamos, para esto tomaremos como referencia (fuera de 3 desviaciones estándar), una regla de la estadística basada en la distribución normal; la regla a usar será la regla empírica del 68-95-99.7% para distribuciones normales y su uso para detección de valores atípicos.
 > Regla empirica para la distribución normal (2025, Abril 10).

Por consiguiente si no lo es será reemplazado por la media para los valores numéricos y con la moda para los categóricos.
"""

# ANALISIS DESCRIPTIVOS

print(" Estadísticas descriptivas:\n")
print(df_base[["Edad", "Deuda", "Años_empleo", "Calificación_crediticia", "Ingresos"]].describe())

print("\n Medianas:\n")
print(df_base[["Edad", "Deuda", "Años_empleo", "Calificación_crediticia", "Ingresos"]].median())

print("\n Desviación estándar:\n")
print(df_base[["Edad", "Deuda", "Años_empleo", "Calificación_crediticia", "Ingresos"]].std())

# Gráfico de cajas para vizualizar los Outliers
plt.figure(figsize=(12, 6))
for i, col in enumerate(["Edad", "Deuda", "Años_empleo", "Calificación_crediticia", "Ingresos"]):
    plt.subplot(2, 3, i + 1)
    sns.boxplot(x=df_base[col])
    plt.title(f'Boxplot - {col}')
plt.tight_layout()
plt.show()

"""Podemos analizar según el resultado de los gráficos que todas las variables presentan outliers; sus distribuciones son asimétricas.

#Tratamiento para Outliers Numéricos
"""

def tratar_outliers(df_base, columnas):
    for col in columnas:
        media = df_base[col].mean()
        std = df_base[col].std()

        lim_inf = media - 3 * std
        lim_sup = media + 3 * std

        extremos = df_base[(df_base[col] < lim_inf) | (df_base[col] > lim_sup)]
        df_base[col] = df_base[col].apply(lambda x: media if x < lim_inf or x > lim_sup else x)
        print(f"Outliers tratados en '{col}': {len(extremos)}")
    return df_base

# Aplicar la función a las variables numéricas
df_base = tratar_outliers(df_base, ["Edad", "Deuda", "Años_empleo", "Calificación_crediticia", "Ingresos"])

"""Definimos un método para reemplazar o eliminar los outliers numéricos, teniendo en cuenta la regla empirica para la distribución normal, comentada arriba anteriormente.
  
  La función calcula la media y la desviasión estandar. Se crearon 2 variables las cuales son las encargadas de establecer nuestro límite inferior (-3), como nuestro límite superior (+3), luego identificamos los valores extremos de la columna y los guardamos para contarlos e informar cuántos se reemplazarán.

  La función **lambda**, para este caso se definió que para cada valor **x** en la columna, Si **x** es menor que el límite inferior o mayor que el límite superior (outlier extremo), este reemplaza **x** por la media; Si no, deja a **x** sin cambios.

  Para finalmente aplicar esta función a toda la columna con **apply()**.
  Como resultado tenemos la cantidad de Outliers tratados por columna.

#Tratamiento Para Outliers Categóricos
"""

for col in col_cat:
    moda = df_base[col].mode()[0]
    freqs = df_base[col].value_counts()
    categorias_raras = freqs[freqs < 0.01 * len(df_base)].index
    df_base[col] = df_base[col].apply(lambda x: moda if x in categorias_raras else x)
    if len(categorias_raras) > 0:
      print(f"Categorías poco frecuentes reemplazadas en '{col}': {list(categorias_raras)}")

"""Para tratar estos outliers utilicé un ciclo **for** teniendo en cuenta que ya se tenía una variable anteriormente llamada **col_cat** y reemplaza las categorías poco frecuentes por la **moda** de cada columna. Se creó variable **freqs** para contar la frecuencia de cada categoría en la columna. Se definen como **(categorias_raras)** todas aquellas cuya frecuencia representa menos del 1% del total de registros.

Nuevamente usé la función **lambda** para cada valor **x** de la columna, indicandole que si **x** pertenece a las **categorias_raras**, lo reemplaza por la **moda**; si no, deja el valor **x** tal como está.

Para finalmente con **len** indicarle que si encuentra una categoría rara indique cual fue y que columna se reemplazó.

#6. GRÁFICOS Y ANALISIS

En este apartado se realizarán gráficos exploratorios para tener un analísis más formal y ayudar en la toma de desiciones ante alguna problemática con respecto a estos datos.
"""

# Gráfico 1: Histograma de Edad
plt.subplot(2, 3, 1)
sns.histplot(df_base['Edad'], kde=True, bins=20, color='skyblue')
plt.title("Distribución de Edad")

"""Este gráfico nos muestra la istribución por edad de la base, la cual se ve ligeramente sesgada hacía la derecha, indicando una distribución unimodal, y concluyendo que la mayoría de los solicitantes se encuentran entre los 20 y 40 años."""

# Gráfico 2: Scatterplot Edad vs Ingresos (coloreado por aprobación)

sns.scatterplot(x='Edad', y='Ingresos', hue='Aprobado', data=df_base)
plt.title("Edad vs Ingresos según Aprobación")

"""Para este gráfico se está comparando la edad vs los ingresos por aprobación, evidenciando que los ingresos altos se aprueban más, de la misma manera que no hay muchas aprobaciones con ingresos cercanos a cero.

Podemos concluir que entre estas dos variables hay una gran relación entre ingresos y la probabilidad de aprobación.
"""

# Gráfico 3: Countplot de Aprobación
plt.subplot(2, 3, 4)
sns.countplot(x='Aprobado', data=df_base, palette='pastel')
plt.title("Frecuencia de Aprobación")

"""En este gráfico se busco saber la frecuencia en la que se aprueban los créditos, dando como resultado que más solicitudes son rechazadas que aprobadas.

Concluyendo que el sistema de crédito es exigente o el perfil general es riesgoso.
"""

# Gráfico 4: Boxplot Edad según Sexo
plt.subplot(2, 3, 5)
sns.boxplot(x='Sexo', y='Edad', data=df_base, palette='cool')
plt.title("Edad por Sexo")

"""En este gráfico se buscó comparar variables categóricas (Sexo) con numéricas (Edad), dando como resultado que tanto hombres (b), como mujeres (a) tienen distribuciones de edades similares. Por lo que se puede concluir que no hay diferencias significativas por sexo en cuanto a edad."""

# Gráfico 6: Heatmap de Correlaciones
sns.heatmap(df_base.corr(numeric_only=True), annot=True, cmap='coolwarm')
plt.title("Correlación entre variables numéricas")

"""Para finalizar se realizó un mapa de correlación entre las variables numéricas del conjunto de datos. Se observa que todos los valores se encuentran positivos y van de 0.096 a 1, lo cual sugiere que no hay relaciones negativas entre las variables numéricas.

De este grafico se puede concluir diferentes aspectos como:
- La calificación crediticia es el predictor más fuerte del resultado (Aprobado), lo cual es coherente con prácticas estándar de análisis crediticio.
- Años de empleo e ingresos también influyen positivamente en la aprobación del crédito, aunque con menor intensidad.
- Variables como edad y deuda tienen correlaciones bajas, por lo que podrían no ser tan determinantes.
- Todas las correlaciones están por debajo de (0.5), lo que es positivo para futuros modelos predictivos.

#BIBLIOGRAFIAS

1. Regla empirica para la distribución normal. *https://builtin.com/data-science/empirical-rule*

2. Diccionario de datos. *https://rstudio-pubs-static.s3.amazonaws.com/73039_9946de135c0a49daa7a0a9eda4a67a72.html*

3. Función Lambda. *https://www.datacamp.com/es/tutorial/python-lambda-functions#:~:text=Las%20funciones%20lambda%20de%20Python%20son%20una%20potente%20herramienta%20para,consulta%20los%20recursos%20de%20DataCamp.*

#Ejercicio Unidad 2 Aprende y mejora

#Estudiante: Leonardo Torres Velilla

De acuerdo con la actividad establecida para la unidad 2 realizaremos en base al ejercicio pasado los puntos que nos indican.

1- Utilizar tres técnicas de agrupamiento, con el objetivo de describir el comportamiento financiero de los individuos que han solicitado un crédito. Identificar patrones y segmentos demográficos y crediticios para una mejor comprensión.

2- Aplicar tres técnicas de clasificación donde Y=A16. Buscar un modelo que permita proyectar si a un individuo se le otorgará o no un crédito financiero según sus variables de entrada.

3- Para cada método de agrupamiento y clasificación, explorar diversas configuraciones de los parámetros de los modelos. Evaluar el rendimiento mediante medidas de desempeño adecuadas para cada técnica utilizada.

Teniendo en cuenta lo realizado en la unidad anterior, tenemos como punto de partida:



*   Se aplicó limpieza en los valores faltantes.
*   Los outliers numéricos y categóricos fueron tratados.
*   La variable Aprobado se encuentra transformada.
"""

df_base.to_csv("credit_data_limpio.csv", index=False)

"""#1 - TÉCNICAS DE AGRUPAMIENTO

las tecnicas elegidas para este punto fueron:
- Análisis de Componentes Principales (PCA)
- Clustering con K-means
- Clustering con DBSCAN

Antes de aplicar las tecnicas primero debemos tener en cuenta que debemos codificar nuestras variables categóricas, dado a que los algoritmos de **clustering** requieren variables númericas.

por lo cual usaremos **labelEncoder**, es una clase de la librería Scikit-learn que se utiliza para transformar etiquetas categóricas en valores numéricos enteros.

Los algoritmos de clustering como **K-Means** y **DBSCAN** no pueden trabajar con datos tipo texto, ya que requieren distancias numéricas entre observaciones.
LabelEncoder asigna un valor numérico distinto a cada categoría, por ejemplo:

* Sexo: ('b': 1, 'a': 0)
* Casado: ('u' : 1, 'y' : 0)
"""

from sklearn.preprocessing import LabelEncoder

# Identificar columnas categóricas que son tipo objeto
cat_cols = df_base.select_dtypes(include='object').columns

# Aplicar clase LabelEncoder
le = LabelEncoder()
for col in cat_cols:
    df_base[col] = le.fit_transform(df_base[col])

"""El siguiente paso a seguir es un escalado de variables, esto con el fin de reducir aquellas variables como Ingresos o Calificación_crediticia que tienen rangos muy distintos.

El clustering calcula distancias euclidianas, por lo que sin escalado, las variables con mayor rango dominarían el resultado. para este paso se transformarán todos los datos para que tengan media 0 y desviación estándar 1.
"""

from sklearn.preprocessing import StandardScaler

# Separar variables predictoras (sin 'Aprobado')
X = df_base.drop('Aprobado', axis=1)

# uso de Escalado
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X.head(10)

"""# 1.1 Técnica de agrupamiento 1
# Análisis de Componentes Principales (PCA)

Tambíen llamado Análisis de componentes es una técnica que se utiliza para reducir la dimensionalidad de los datos. El PCA crea nuevas variables, como componentes principales, que son combinaciones lineales de las variables originales.
"""

from sklearn.decomposition import PCA

pca = PCA(n_components=3)
pca.fit_transform(X_scaled)

"""Este código aplica Análisis de Componentes Principales (PCA) al conjunto de datos escalado (X_scaled) con el objetivo de reducir su dimensionalidad a 3 componentes principales."""

data_pca = pca.fit_transform(X_scaled)

print(pca.explained_variance_ratio_)

"""Esto significa que las tres primeras componentes principales (PC) extraídas mediante PCA explican las siguientes proporciones de la varianza total del conjunto de datos:

![image.png](data:image/png;base64,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)

Esto evidencia que solo el 40.94% de la varianza total de los datos originales está contenida en estas 3 dimensiones.
"""

print(pca.explained_variance_ratio_.cumsum())

"""Esta parte nos da a entender que nuestra varianza acumulada es aproximadamente de un 40.95%."""

print(pca.components_)

"""#1.2 Tenica de agrupamiento 2
#K- Means

Esta técnica busca k grupos distintos en los datos, cada grupo se representa por un centroide y Asigna cada observación al grupo cuyo centroide esté más cercano.

Para aplicar los k-means, primero utilizamos el método del codo, esto con el fin de identificar el número óptimo de clusters para la técnica.

A continuación, gráficaremos y buscaremos identificar el punto donde la disminución de la inercia comienza a volverse menos pronunciada
"""

inercia = []

for i in range(2,10):
  cluster = KMeans(n_clusters=i,random_state=42)
  cluster.fit(data_pca)
  inercia.append(cluster.inertia_)

plt.plot(range(2,10),inercia, marker='x')
plt.xlabel('Número de clusters')
plt.ylabel('Inercia')
plt.title('Gráfico de la técnica del codo')
plt.show()

"""Tal como se evidencia en la gráfica, podemos concluir que el número óptimo de clústeres sugerido por este gráfico es 3.

Esto significa que, según la distribución y compactación de los datos financieros se identifican naturalmente 3 segmentos o grupos de individuos.
"""

from sklearn.cluster import KMeans

grupos = KMeans(n_clusters=3, random_state=42)
grupos.fit(X_scaled)

print(grupos.labels_)

data_final = pd.DataFrame(data_pca, columns=['PCA1','PCA2','PCA3'])

data_final['grupos'] = grupos.labels_

sns.scatterplot(data=data_final,x='PCA1',y='PCA2',hue='grupos',palette='viridis')
plt.title('Clusters con K-Means')
plt.xlabel('Componente Principal 1')
plt.ylabel('Componente Principal 2')
plt.show()

"""Este gráfico muestra el resultado visual del algoritmo de agrupamiento K-Means, aplicado sobre los datos de solicitantes de crédito después de haberlos reducido a dos componentes principales mediante Análisis de Componentes Principales (PCA).

Cada punto es un individuo (solicitante de crédito).

El color representa a qué grupo (clúster) pertenece según el algoritmo K-Means.

- Grupo 0 (púrpura)
- Grupo 1 (verde azulado)
- Grupo 2 (amarillo)

El algoritmo detectó patrones en los datos y agrupó a los solicitantes en 3 grupos distintos, basados en similitud de características.

Las agrupaciones están bien separadas en el plano, lo que indica que:

El clustering fue exitoso.

Hay diferencias claras entre los perfiles de cada grupo.

Por ejemplo, un grupo puede tener personas con alta deuda e ingresos bajos; otro, personas con buena calificación crediticia y años de empleo estables.

En conclusión, este gráfico te permite validar visualmente que K-Means fue efectivo al separar los datos en grupos significativos. No es el análisis final, pero sí ayuda a identificar patrones y caracterizar los grupos después.
"""

#Añadí al dataset la columna llamada grupos
df_base['grupos'] = grupos.labels_
df_base.head()

# Agrupamiento por grupos para las primeras 5 filas
data_segmentada = df_base.groupby('grupos')

for label, data in data_segmentada:
  print(f'grupos:{label}')
  print(data.head(5))
  print('/n')

"""Tomando en cuenta está agrupación se observa:

**Grupo 0** Jóvenes en situación vulnerable (Edad entre 20 y 33 años)

Este grupo representa jóvenes sin empleo ni historial bancario, con historial de incumplimiento y alta deuda.

La aprobación de crédito en todos los casos es sorprendente, lo que sugiere que podrían estar accediendo a microcréditos o subsidios sin evaluación exhaustiva.

Potencialmente alto riesgo crediticio para entidades financieras tradicionales.

**Grupo 1** Adultos con empleo y calificación intermedia (Edad entre 27 y 58 años)

Tienen mejor perfil que el grupo 0, especialmente por el empleo y calificación. A pesar de algunos ingresos bajos, parecen estar siendo aprobados por tener empleo y mejor historial crediticio.

Este grupo es moderado en riesgo, y podría beneficiarse de programas de inclusión con educación financiera.

**Grupo 2** Clientes formales pero con señales mixtas (Mayores de 36 años y mayores de 50 años)

Este grupo es el más estable formalmente, pero con gran heterogeneidad. Algunos podrían ser clientes tradicionales en proceso de caída financiera, y otros con mal historial a pesar de estar bancarizados.

Se recomienda segmentarlos internamente con un análisis más fino ya sea por calificación o ingresos.

#1.3 Tenica de agrupamiento 3
#Clustering con DBSCAN

es un algoritmo de clustering que agrupa puntos de datos en función de su densidad. A diferencia de otros algoritmos, DBSCAN no requiere especificar el número de clusters de antemano y es capaz de identificar ruido (puntos que no pertenecen a ningún cluster).

A continuación, se agruparán los datos según densidad, sin especificar el número de clústeres.
"""

from sklearn.cluster import DBSCAN

dbscan = DBSCAN(eps=1.5, min_samples=5)
dbscan_labels = dbscan.fit_predict(X_scaled)

"""Este algoritmo,

- Detecta grupos densos de puntos.
- No requiere definir cuántos grupos hay.
- Puntos aislados se consideran ruido (-1).
"""

plt.figure(figsize=(8, 6))
sns.scatterplot(x=data_pca[:, 0], y=data_pca[:, 1], hue=dbscan_labels, palette='Dark2')
plt.title("Clustering con DBSCAN")
plt.xlabel("Componente Principal 1")
plt.ylabel("Componente Principal 2")
plt.legend(title="Cluster")
plt.show()

"""Interpretación del gráfico:

- Eje X: Componente Principal 1
- Eje Y: Componente Principal 2

Estos componentes son combinaciones lineales de las variables originales y retienen la mayor varianza posible. No son interpretables directamente como variables originales, pero sí reflejan la estructura global de los datos.

Se identificaron 9 clusters válidos (0 a 8), el color de cada punto indica a qué cluster pertenece.

Los puntos identificados como -1 (ruido), aparecen en verde oscuro, estos representan outliers o puntos que no pertenecen a ningún grupo denso. Su presencia es útil para entender casos atípicos (posibles fraudes, errores de registro, comportamientos financieros muy distintos).

Para la Distribución, se identifica que hay dos regiones principales de densidad alta, visibles como agrupaciones al norte y al sur del gráfico.

Los clusters están embebidos dentro de estas regiones, lo que sugiere que dentro de patrones similares hay subgrupos con características distintas.

Para concluir teniendo en cuenta el análisis financiero para el estudio crediticio podriamos inferir que para los clústers válidos (0 a 8), los subgrupos de clientes con comportamientos financieros similares por ejemplo, clientes con ingresos estables, clientes nuevos, de alto riesgo, etc.. Se deben analizar sus características originales tales como la edad, ingresos, historial, entre otras, con el fin de tener una mejor interpretación.

por el contrario para los puntos (-1) se infiere que son individuos anómalos, que se salen del patrón de todos los grupos, podrían representar clientes con comportamiento inusual como: muy alta deuda, ingresos nulos, historial errático o extremadamente bueno.

#2. TÉCNICAS DE CLASIFICACIÓN

Las técnicas usadas para este punto fueron las siguientes:
- Regresión Logística.
- Naive Bayes (GaussianNB)
- Árbol de Desición
- K Vecinos más cercanos (KNN)

Tal como el ejercicio indica tomaremos en cuenta las técnicas de clasificación utilizando la librería scikit-learn, con la variable: **Aprobado** como variable objetivo (Y), y dividiendo el conjunto en entrenamiento y prueba con train_test_split.

para este apartado tomaremos la transformación de datos previamente realizada para las técnicas de agrupamiento, dado a que los datos procesados deben estar sin nulos, sin variables categóricas sin codificar, y con el X_escalado anteriormente realizado. Es necesario también que Aprobado esté en formato numérico, el cual ya se encuentra transformado.
"""

from sklearn.model_selection import train_test_split

# Separar variables predictoras (X) y variable objetivo (Y)
X = df_base.drop(columns=['Aprobado'])
Y = df_base['Aprobado']

# Dividir el conjunto en entrenamiento y prueba
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)

"""# 2.1 Técnica 1
# Regresión Logística

"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix

log_model = LogisticRegression(max_iter=1000)
log_model.fit(X_train, Y_train)
Y_pred_log = log_model.predict(X_test)

print("Regresión Logística:")
print(confusion_matrix(Y_test, Y_pred_log))
print(classification_report(Y_test, Y_pred_log))

"""De acuerdo a los resultados podemos deducir que esta técnica presenta un buen equilibrio entre precisión y recall.

Especialmente fuerte en el recall para los aprobados (1), lo cual significa que identifica correctamente la mayoría de los individuos a los que se les aprueba el crédito.

Es un modelo lineal, útil cuando los datos tienen separación clara entre clases.

tiene como ventaja:
- Fácil de interpretar
- rápido y eficiente.

# 2.2 Técnica 2
# Naive Bayes (GaussianNB)
"""

from sklearn.naive_bayes import GaussianNB

nb_model = GaussianNB()
nb_model.fit(X_train, Y_train)
Y_pred_nb = nb_model.predict(X_test)

print("Naive Bayes:")
print(confusion_matrix(Y_test, Y_pred_nb))
print(classification_report(Y_test, Y_pred_nb))

"""De acuerdo a los resultados podemos deducir que esta técnica presenta alta precisión en clase 1: cuando predice *aprobado*, suele acertar.

Sin embargo, su recall es más bajo que en Regresión Logística: se le escapan más casos que deberían ser aprobados.

Naive Bayes asume independencia entre variables, lo que rara vez se cumple en problemas financieros.

Puede ser útil cuando el objetivo es minimizar falsos positivos para evitar dar crédito a quien no lo merece, aunque corre el riesgo de no aprobar a clientes buenos.

# 2.3 Técnica 3
# Árbol de Decisión (Decision Tree)
"""

from sklearn.tree import DecisionTreeClassifier

tree_model = DecisionTreeClassifier(random_state=42)
tree_model.fit(X_train, Y_train)
Y_pred_tree = tree_model.predict(X_test)

print("Árbol de Decisión:")
print(confusion_matrix(Y_test, Y_pred_tree))
print(classification_report(Y_test, Y_pred_tree))

"""De acuerdo a los resultados podemos deducir que esta técnica ofrece un rendimiento equilibrado.

Tiene mejor precisión que Naive Bayes y una ligera desventaja en recall respecto a Regresión Logística.

Fácil de interpretar visualmente puesto que puede convertirse en reglas lógicas.

Como una Ventaja clave:
- Puede modelar relaciones no lineales entre variables sin requerir normalización.

# 2.4 Técnica 4
# K Vecinos más Cercanos (KNN)
"""

from sklearn.neighbors import KNeighborsClassifier

knn_model = KNeighborsClassifier(n_neighbors=5)  # Puedes ajustar k
knn_model.fit(X_train, Y_train)
Y_pred_knn = knn_model.predict(X_test)

print("K Vecinos (KNN):")
print(confusion_matrix(Y_test, Y_pred_knn))
print(classification_report(Y_test, Y_pred_knn))

"""De acuerdo a los resultados podemos deducir que esta técnica ofrece un rendimiento claramente inferior en todas las métricas.

Tiene bajo recall y precisión indica que confunde mucho ambas clases. Es altamente sensible a la escala de los datos y al ruido.

En este caso, no parece una buena técnica para clasificación crediticia, al menos sin ajuste de hiperparámetros o ingeniería de características más profunda.

# CONCLUSIONES GENERALES

De acuerdo con el siguiente cuadro comparativo, se podrá observar una comparativa entre las diferentes técnicas de clasificación que se hicieron:

![image.png](data:image/png;base64,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)

Por lo cual podemos indducir que la mejor técnica para este caso es la **Regresión Logística**, porque:

1. Tiene la mayor capacidad de detección correcta de aprobaciones (recall = 0.86), lo cual es fundamental para no perder clientes viables.

2. Ofrece buen balance general de métricas.

3. Es robusta y fácil de interpretar, ideal para justificar decisiones en entornos financieros donde la trazabilidad es clave.

Con respecto a las demás técnicas, Naive Bayes y Árbol de Decisión son opciones razonables, pero con desventajas comparativas claras frente a la regresión logística. Y por último KNN queda descartado, debido a ser la que menos opción para calificación crediticia tiene.

#BIBLIOGRAFIAS

*LabelEncoder.* https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html

*StandarScaler.* https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html

*Análisis de Componentes Principales (PCA).* https://www.ibm.com/es-es/think/topics/principal-component-analysis#:~:text=El%20PCA%20se%20utiliza%20para,los%20objetivos%20de%20su%20an%C3%A1lisis.

*Método del codo.* https://www.ibm.com/mx-es/think/topics/k-means-clustering#:~:text=El%20m%C3%A9todo%20del%20codo&text=Mide%20la%20distancia%20euclidiana%20entre,funci%C3%B3n%20del%20n%C3%BAmero%20de%20cl%C3%BAsteres.&text=El%20primer%20paso%20del%20m%C3%A9todo,el%20n%C3%BAmero%20%C3%B3ptimo%20de%20cl%C3%BAsteres.&text=A%20la%20hora%20de%20decidir,el%20an%C3%A1lisis%20de%20la%20silueta.

*Machine Learning & Clustering: el algoritmo DBSCAN.* https://datascientest.com/es/machine-learning-clustering-dbscan

*Algoritmo de clasificación: definición y modelos principales.* https://datascientest.com/es/algoritmo-de-clasificacion#:~:text=Clasificaci%C3%B3n%20supervisada,en%20lugar%20de%20una%20categor%C3%ADa.

*Machine learning: Diferencias entre algoritmos de clasificación y regresión.* https://theblackboxlab.com/machine-learning-diferencias-entre-algoritmos-clasificacion-regresion/
"""